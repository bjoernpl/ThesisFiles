{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRS3 Split audio and transcriptions into sections of 3.5 to 8.5 seconds\n",
    "\n",
    "The idea here is to look at the transcription for each utterance, where the timings of the words are declared. \n",
    "\n",
    "Using this information,we will split the audio files as well as the transcriptions into utterances of more equal length.\n",
    "\n",
    "We will take segments of ~5 seconds\n",
    "length by always splitting after the first word that crosses the n\\*5 seconds mark. If the last segment were to be less than 3.5\n",
    "seconds long, it will be added to the previous segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from more_itertools import ilen\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/mnt/U/Datasets/lrs3pretrain/raw/pretrain\")\n",
    "audio_data_dir = Path(\"/mnt/U/Datasets/lrs3pretrain/processed/audio/pretrain/\")\n",
    "text_dir = Path(\"/mnt/U/Datasets/lrs3pretrain/processed/text/pretrain/\")\n",
    "segments_dir = Path(\"/mnt/U/Datasets/lrs3pretrain/processed/audio_segments/pretrain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = list(data_dir.glob(\"*\"))\n",
    "utt_per_spk = {}\n",
    "for speaker in speakers:\n",
    "    aud_speaker = audio_data_dir / speaker.name\n",
    "    wavs = list(aud_speaker.glob(\"*.wav\"))\n",
    "    txts = [data_dir / speaker.name / (wav.stem + \".txt\") for wav in wavs]\n",
    "    utt_per_spk[speaker.name] = (wavs, txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example transcription file:\n",
    "    Text:  TO SHOW IT TO YOU NOT BECAUSE I WANT TO GIVE YOU THE KIND OF STARBUCKS TOUR OF HISTORIC ENGLAND BUT \n",
    "    Conf:  2\n",
    "\n",
    "    WORD START END ASDSCORE\n",
    "    TO 0.09 0.15 12.9\n",
    "    SHOW 0.15 0.37 12.7\n",
    "    IT 0.37 0.47 8.2\n",
    "    TO 0.47 0.53 6.6\n",
    "    YOU 0.53 0.61 6.6\n",
    "    NOT 0.61 0.80 7.6\n",
    "    BECAUSE 0.80 1.01 7.1\n",
    "    I 1.01 1.09 6.3\n",
    "    WANT 1.09 1.24 6.1\n",
    "    TO 1.24 1.30 6.3\n",
    "    GIVE 1.30 1.40 6.0\n",
    "    YOU 1.40 1.49 4.6\n",
    "    THE 1.49 1.59 3.7\n",
    "    KIND 1.59 1.89 3.9\n",
    "    OF 2.14 2.40 8.8\n",
    "    STARBUCKS 2.40 3.04 8.4\n",
    "    TOUR 3.04 3.45 6.5\n",
    "    OF 3.45 3.66 4.2\n",
    "    HISTORIC 3.84 4.24 7.3\n",
    "    ENGLAND 4.24 4.73 6.6\n",
    "    BUT 4.88 5.37 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_times(text_path):\n",
    "    out = []\n",
    "    with open(text_path, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "        for word_data in lines[4:]:\n",
    "            word, start, end, _ = word_data.split(\" \")\n",
    "            out.append((word, start, end))\n",
    "    return out\n",
    "\n",
    "def get_segments(word_times, min_len=3.5, seg_len=5.0):\n",
    "    segs = []\n",
    "    last = 0\n",
    "    total_time = float(word_times[-1][-1])\n",
    "    for i in range(1,math.ceil(total_time/seg_len)+1):\n",
    "        seg_start = None\n",
    "        seg_words = []\n",
    "        for x in range(last, len(word_times)):\n",
    "            word, start, end = word_times[x]\n",
    "            seg_words += [word]\n",
    "            if not seg_start:\n",
    "                seg_start = start\n",
    "            if float(end) > i*seg_len:\n",
    "                segs.append((seg_words, float(seg_start), float(end)))\n",
    "                last = x+1\n",
    "                break\n",
    "            elif x == len(word_times)-1:\n",
    "                segs.append((seg_words, float(seg_start), float(end)))\n",
    "    last_words, last_start, last_end = segs[-1]\n",
    "    if (last_end - last_start <= min_len) and (last != len(word_times)) and (len(segs) > 1):\n",
    "        del segs[-1]\n",
    "        p_last_words, p_last_start, p_last_end = segs[-1]\n",
    "        p_last_words += last_words\n",
    "        p_last_end = last_end\n",
    "        segs[-1] = (p_last_words, p_last_start, p_last_end)\n",
    "    segs = [(\" \".join(words), start, end) for words, start, end in segs]\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_utts = []\n",
    "for spk, (utts, texts) in utt_per_spk.items():\n",
    "    spk_utts += [(spk, utts[i], texts[i]) for i in range(len(utts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "for spk, utt, text in tqdm(spk_utts):\n",
    "    word_times = get_word_times(text)\n",
    "    segs = get_segments(word_times)\n",
    "    for i, (txt, start, end) in enumerate(segs):\n",
    "        aud_path = segments_dir / spk / f\"{utt.stem}_{i}.wav\"\n",
    "        if not aud_path.exists():\n",
    "            if not aud_path.parent.exists():\n",
    "                aud_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            txt_path = text_dir / spk / f\"{text.stem}_{i}.txt\"\n",
    "            if not txt_path.parent.exists():\n",
    "                txt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if not txt_path.exists():\n",
    "                with open(txt_path, \"w\") as f:\n",
    "                    f.writelines([txt])\n",
    "            segments.append((utt, aud_path, start, end))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_time(t):\n",
    "    minutes = math.floor(t/60)\n",
    "    seconds = t - minutes * 60\n",
    "    ms = t % 1.0\n",
    "    return f\"00:{minutes:02.0f}:{int(seconds):02.0f}.{(t-int(t))*1000:03.0f}\"\n",
    "\n",
    "def cut_segment(data):\n",
    "    utt, aud_path, start, end = data\n",
    "    from_string = to_time(start)\n",
    "    to_string = to_time(end)\n",
    "    !ffmpeg -i {utt} -ss {from_string} -to {to_string} -codec copy {aud_path} -loglevel quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Pool(32)\n",
    "list(tqdm(p.imap_unordered(cut_segment, segments), total=len(segments)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esptest3",
   "language": "python",
   "name": "esptest3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
